{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import MovieLens\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "        # z = torch.cat([z_dict['user'][row], z_dict['movie'][col]], dim=-1)\n",
    "        z = torch.cat([z_dict['u'][row], z_dict['v'][col]], dim=-1)\n",
    "\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z)\n",
    "        return z.view(-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.decoder(z_dict, edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'./ml-latest-small/ratings.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100836, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['if'] = df['rating'].apply(lambda x: 1 if x>3.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    52256\n",
       "1    48580\n",
       "Name: if, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['if'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_node(col):\n",
    "    # x = torch.rand(len(col.unique()), 100, device=device)\n",
    "    mapping = {id_: i for i, id_ in enumerate(col.unique())}\n",
    "    x = torch.eye(len(col.unique()))\n",
    "    return x, mapping\n",
    "\n",
    "def load_edge(src, dst, u_mapping, v_mapping):\n",
    "    src_mapping = [u_mapping[u] for u in src.tolist()]\n",
    "    dst_mapping = [v_mapping[v] for v in dst.tolist()]\n",
    "\n",
    "    return torch.tensor([src_mapping, dst_mapping], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mu\u001b[0m={ x=[610, 610] },\n",
       "  \u001b[1mv\u001b[0m={ x=[9724, 9724] },\n",
       "  \u001b[1m(u, r, v)\u001b[0m={\n",
       "    edge_index=[2, 100836],\n",
       "    edge_label=[100836]\n",
       "  },\n",
       "  \u001b[1m(v, rev_r, u)\u001b[0m={ edge_index=[2, 100836] }\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = HeteroData()\n",
    "ux, u_mapping = load_node(df['userId'])\n",
    "vx, v_mapping = load_node(df['movieId'])\n",
    "\n",
    "data['u'].x = ux\n",
    "data['v'].x = vx\n",
    "data['u', 'r', 'v'].edge_index = load_edge(df['userId'], df['movieId'], u_mapping, v_mapping)\n",
    "data['u', 'r', 'v'].edge_label = torch.tensor(df['if'].tolist(), device=device)\n",
    "\n",
    "data = T.ToUndirected()(data)\n",
    "del data['v', 'rev_r', 'u'].edge_label\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HeteroData(\n",
    "#   movie={ x=[9742, 404] },\n",
    "#   user={ x=[610, 610] },\n",
    "#   (user, rates, movie)={\n",
    "#     edge_index=[2, 100836],\n",
    "#     edge_label=[100836]\n",
    "#   },\n",
    "#   (movie, rev_rates, user)={ edge_index=[2, 100836] }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = T.AddSelfLoops()(data)\n",
    "data = T.NormalizeFeatures()(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to(device=device)\n",
    "\n",
    "train_data, val_data, test_data = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    neg_sampling_ratio=0.0,\n",
    "    edge_types=[('u', 'r', 'v')],\n",
    "    rev_edge_types=[('v', 'rev_r', 'u')],\n",
    ")(data)\n",
    "\n",
    "# use_weighted_loss = True\n",
    "# # We have an unbalanced dataset with many labels for rating 3 and 4, and very\n",
    "# # few for 0 and 1. Therefore we use a weighted MSE loss.\n",
    "# if use_weighted_loss:\n",
    "#     weight = torch.bincount(train_data['u', 'v'].edge_label)\n",
    "#     weight = weight.max() / weight\n",
    "# else:\n",
    "#     weight = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
    "                 train_data['u', 'v'].edge_label_index)\n",
    "    target = train_data['u', 'v'].edge_label\n",
    "    loss = criterion(pred, target.float())\n",
    "    # loss = weighted_mse_loss(pred, target, weight)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict,\n",
    "                 data['u', 'v'].edge_label_index)\n",
    "    pred = pred.clamp(min=0, max=1)\n",
    "    pred = torch.sigmoid(pred)\n",
    "    target = data['u', 'v'].edge_label\n",
    "    log_loss_ = log_loss(target.cpu().numpy().astype(int), pred.cpu().numpy())\n",
    "    \n",
    "    return float(log_loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sag = SAGEConv((-1, -1), 32)\n",
    "# sag_ = to_hetero(sag, data.metadata(), aggr='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sag(train_data.x_dict['u'], train_data.edge_index_dict[('u', 'r', 'v')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(hidden_channels=32).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Due to lazy initialization, we need to run one model step so the number\n",
    "# of parameters can be inferred:\n",
    "with torch.no_grad():\n",
    "    model.encoder(train_data.x_dict, train_data.edge_index_dict)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6930, Train: 0.6925, Val: 0.6925, Test: 0.6926\n",
      "Epoch: 002, Loss: 0.6924, Train: 0.6931, Val: 0.6931, Test: 0.6931\n",
      "Epoch: 003, Loss: 0.6897, Train: 0.6931, Val: 0.6931, Test: 0.6931\n",
      "Epoch: 004, Loss: 0.6855, Train: 0.6911, Val: 0.6915, Test: 0.6916\n",
      "Epoch: 005, Loss: 0.6764, Train: 0.6814, Val: 0.6830, Test: 0.6839\n",
      "Epoch: 006, Loss: 0.6614, Train: 0.6667, Val: 0.6700, Test: 0.6727\n",
      "Epoch: 007, Loss: 0.6416, Train: 0.6531, Val: 0.6584, Test: 0.6634\n",
      "Epoch: 008, Loss: 0.6185, Train: 0.6447, Val: 0.6519, Test: 0.6589\n",
      "Epoch: 009, Loss: 0.5940, Train: 0.6416, Val: 0.6509, Test: 0.6577\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    loss = train()\n",
    "    train_rmse = test(train_data)\n",
    "    val_rmse = test(val_data)\n",
    "    test_rmse = test(test_data)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
    "          f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'./'\n",
    "dataset = MovieLens(path, model_name='all-MiniLM-L6-v2')\n",
    "data = dataset[0].to(device)\n",
    "\n",
    "# Add user node features for message passing:\n",
    "data['user'].x = torch.eye(data['user'].num_nodes, device=device)\n",
    "del data['user'].num_nodes\n",
    "\n",
    "# Add a reverse ('movie', 'rev_rates', 'user') relation for message passing:\n",
    "data = T.ToUndirected()(data)\n",
    "del data['movie', 'rev_rates', 'user'].edge_label  # Remove \"reverse\" label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovie\u001b[0m={ x=[9742, 404] },\n",
       "  \u001b[1muser\u001b[0m={ x=[610, 610] },\n",
       "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
       "    edge_index=[2, 100836],\n",
       "    edge_label=[100836]\n",
       "  },\n",
       "  \u001b[1m(movie, rev_rates, user)\u001b[0m={ edge_index=[2, 100836] }\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9741, device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['user', 'rates', 'movie'].edge_index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform a link-level split into training, validation, and test edges:\n",
    "train_data, val_data, test_data = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    neg_sampling_ratio=0.0,\n",
    "    edge_types=[('user', 'rates', 'movie')],\n",
    "    rev_edge_types=[('movie', 'rev_rates', 'user')],\n",
    ")(data)\n",
    "\n",
    "use_weighted_loss = True\n",
    "# We have an unbalanced dataset with many labels for rating 3 and 4, and very\n",
    "# few for 0 and 1. Therefore we use a weighted MSE loss.\n",
    "if use_weighted_loss:\n",
    "    weight = torch.bincount(train_data['user', 'movie'].edge_label)\n",
    "    weight = weight.max() / weight\n",
    "else:\n",
    "    weight = None\n",
    "\n",
    "\n",
    "def weighted_mse_loss(pred, target, weight=None):\n",
    "    weight = 1. if weight is None else weight[target].to(pred.dtype)\n",
    "    return (weight * (pred - target.to(pred.dtype)).pow(2)).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
    "                 train_data['user', 'movie'].edge_label_index)\n",
    "    target = train_data['user', 'movie'].edge_label\n",
    "    loss = weighted_mse_loss(pred, target, weight)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict,\n",
    "                 data['user', 'movie'].edge_label_index)\n",
    "    pred = pred.clamp(min=0, max=5)\n",
    "    target = data['user', 'movie'].edge_label.float()\n",
    "    rmse = F.mse_loss(pred, target).sqrt()\n",
    "    return float(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "        z = torch.cat([z_dict['user'][row], z_dict['movie'][col]], dim=-1)\n",
    "\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z)\n",
    "        return z.view(-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.decoder(z_dict, edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
    "                 train_data['u', 'v'].edge_label_index)\n",
    "    target = train_data['u', 'v'].edge_label\n",
    "    loss = criterion(pred, target.float())\n",
    "    # loss = weighted_mse_loss(pred, target, weight)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict,\n",
    "                 data['user', 'movie'].edge_label_index)\n",
    "    pred = pred.clamp(min=0, max=1)\n",
    "    pred = torch.sigmoid(pred)\n",
    "    target = data['user', 'movie'].edge_label\n",
    "    log_loss_ = log_loss(target.cpu().numpy().astype(int), pred.cpu().numpy())\n",
    "    \n",
    "    return float(log_loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(hidden_channels=32).to(device)\n",
    "\n",
    "# Due to lazy initialization, we need to run one model step so the number\n",
    "# of parameters can be inferred:\n",
    "with torch.no_grad():\n",
    "    model.encoder(train_data.x_dict, train_data.edge_index_dict)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EdgeStorage' object has no attribute 'edge_label_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32me:\\Software\\anaconda3\\lib\\site-packages\\torch_geometric\\data\\storage.py:50\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m[key]\n\u001b[0;32m     51\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32me:\\Software\\anaconda3\\lib\\site-packages\\torch_geometric\\data\\storage.py:70\u001b[0m, in \u001b[0;36mBaseStorage.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mapping[key]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'edge_label_index'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\Workplace\\bip_likn_predict.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Workplace/bip_likn_predict.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m301\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Workplace/bip_likn_predict.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     loss \u001b[39m=\u001b[39m train()\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Workplace/bip_likn_predict.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     train_rmse \u001b[39m=\u001b[39m test(train_data)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Workplace/bip_likn_predict.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     val_rmse \u001b[39m=\u001b[39m test(val_data)\n",
      "\u001b[1;32me:\\Workplace\\bip_likn_predict.ipynb Cell 27\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Workplace/bip_likn_predict.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Workplace/bip_likn_predict.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Workplace/bip_likn_predict.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m pred \u001b[39m=\u001b[39m model(train_data\u001b[39m.\u001b[39mx_dict, train_data\u001b[39m.\u001b[39medge_index_dict,\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Workplace/bip_likn_predict.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m              train_data[\u001b[39m'\u001b[39;49m\u001b[39mu\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mv\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49medge_label_index)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Workplace/bip_likn_predict.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m target \u001b[39m=\u001b[39m train_data[\u001b[39m'\u001b[39m\u001b[39mu\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mv\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39medge_label\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Workplace/bip_likn_predict.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(pred, target\u001b[39m.\u001b[39mfloat())\n",
      "File \u001b[1;32me:\\Software\\anaconda3\\lib\\site-packages\\torch_geometric\\data\\storage.py:52\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[key]\n\u001b[0;32m     51\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m     53\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'EdgeStorage' object has no attribute 'edge_label_index'"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 301):\n",
    "    loss = train()\n",
    "    train_rmse = test(train_data)\n",
    "    val_rmse = test(val_data)\n",
    "    test_rmse = test(test_data)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
    "          f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2b388c6fce79e00fd9c43dd7c300c62775de93114fdc7222b9aeb8ab89a5a93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
